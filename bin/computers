#!/usr/bin/env -S ruby --disable-gems

require "tempfile"
require "pathname"

LAST_RUN_AT = "2023-06-01"
$db_path = "/Users/pjaspers/browser/history.db"

def run_sql(sql, db)
  Tempfile.open("some-sql") do |sql_file|
    sql_file.write(sql)
    sql_file.rewind

    `cat #{sql_file.path} | /usr/bin/sqlite3 #{db}`
  end
end

run_sql(<<~SQL, $db_path)
  CREATE TABLE if not exists history (
    id varchar(500) PRIMARY KEY,
    signature TEXT NOT NULL UNIQUE,
    url TEXT NOT NULL UNIQUE,
    visited_at TEXT NOT NULL,
    browser TEXT NOT NULL,
    title TEXT
  );

  CREATE INDEX if not exists idx_title ON "history"(title);
  CREATE INDEX if not exists idx_url ON "history"(url);
  CREATE INDEX if not exists visited_at ON history(title);
SQL

before = `/usr/bin/sqlite3 #{$db_path} "select browser, count(*) from history group by browser";`.strip
before = before.split("\n").inject({}) {|r, s| k, v = s.split("|"); r[k] = v.to_i; r}

config = {firefox: {}, arc: {}, chrome: {}, safari: {}}
path = Pathname.new(File.expand_path("~/Library/Application Support/Firefox/Profiles/"))
config[:firefox][:dbs] = path.glob("*").select {|f| f.directory?}.flat_map do |path|
  path.glob("*.sqlite").select{|f| f.basename.to_s == "places.sqlite"}
end.map(&:to_s)

path = Pathname.new(File.expand_path("~/Library/Application Support/Arc/User Data/"))
config[:arc][:dbs] = path.glob("**/History").map(&:to_s)

path = Pathname.new(File.expand_path("~/Library/Application Support/Google/Chrome/"))
config[:chrome][:dbs] = path.glob("**/History").map(&:to_s)

config[:safari][:dbs] = [File.expand_path("~/Library/Safari/History.db")]
config

sqls = {
  firefox: <<~SQL,
SELECT
  datetime(moz_historyvisits.visit_date/1000000,'unixepoch') as visited_at,
  moz_places.url as url,
  moz_places.title as title,
  'firefox' as browser
FROM
  moz_places,
  moz_historyvisits
WHERE
  moz_places.id = moz_historyvisits.place_id
AND
  datetime(moz_historyvisits.visit_date/1000000,'unixepoch') > '%{datetime}';
SQL
  safari: <<~SQL,
SELECT
  datetime(hv.visit_time + 978307200, 'unixepoch', 'localtime') as visited_at,
  hi.url as url,
  hv.title as title,
  'safari' as browser
FROM
  history_visits hv,
  history_items hi
WHERE
  hv.history_item = hi.id
AND
  datetime(hv.visit_time + 978307200, 'unixepoch', 'localtime') > '%{datetime}';
SQL
  chrome: <<~SQL,
SELECT
  datetime(last_visit_time/1000000-11644473600, "unixepoch") as visited_at,
  url as url,
  title as title,
  'chrome' as browser
FROM
  urls
WHERE
  datetime(last_visit_time/1000000-11644473600, "unixepoch") > '%{datetime}';
SQL
  arc: <<~SQL
SELECT
  datetime(last_visit_time/1000000-11644473600, "unixepoch") as visited_at,
  url as url,
  title as title,
  'arc' as browser
FROM
  urls
WHERE
  datetime(last_visit_time/1000000-11644473600, "unixepoch") > '%{datetime}';
SQL
}
puts "Exporting history after #{LAST_RUN_AT} to csv's..."
sqls.each do |browser, sql|
  config[browser][:dbs].each.with_index(1) do |db_path, index|
    csv_path = "/Users/pjaspers/browser/#{browser}-#{index}.csv"
    raise "No such thing #{db_path}" unless File.exist?(db_path)

    Tempfile.open("#{browser}-db-#{index}") do |copy_of_db|
      # Well, that's one way to copy a sqlite to a temp file
      copy_of_db.write File.open(db_path).read

      Tempfile.open("#{browser}-sql") do |sql_file|
        sql_file.write <<~SQL
          .mode csv
          .output #{csv_path}

          #{sql % {datetime: LAST_RUN_AT}}
        SQL
        sql_file.rewind

        cmd = "cat #{sql_file.path} | /usr/bin/sqlite3 #{copy_of_db.path}"
        `#{cmd}`
      end
    end
  end
end


require "csv"
require "time"
require 'digest/sha1'
require "securerandom"
CHARACTER_FILTER = /[\x00-\x1F\/\\:\*\?\"<>\|]/u
UNICODE_WHITESPACE = /[[:space:]]+/u

puts "Combining into: ~/browser/combined.csv"
Dir.chdir(File.expand_path("~/browser")) do
  files = sqls.flat_map { |browser, _sql| Dir.glob("#{browser}-*").to_a }
  `cat #{files.join(" ")} > combined.csv`
end

Tempfile.open("insert-sql") do |sql_file|
  puts "  Generating inserts"
  sql_file.puts "BEGIN TRANSACTION;"
  CSV.foreach(File.expand_path("~/browser/combined.csv")) do |date,url,title, browser|
    time = Time.parse(date)
    next unless time > Time.parse(LAST_RUN_AT)

    sha = Digest::SHA1.hexdigest(date + url)
    id = SecureRandom.uuid
    title = (title || "").strip.gsub(UNICODE_WHITESPACE,' ').gsub(CHARACTER_FILTER,'').gsub(UNICODE_WHITESPACE,' ').gsub("'", "").gsub('"', "")

    sql = %Q[INSERT OR IGNORE INTO history (id,signature,url, visited_at, title, browser) VALUES ("#{id}", "#{sha}", "#{url.gsub('"', "")}", "#{date}", "#{title}", "#{browser}");]
    sql_file.puts sql
  end
  sql_file.puts "COMMIT;"
  sql_file.rewind

  puts "  Persisting to #{$db_path}"
  `cat #{sql_file.path} | /usr/bin/sqlite3 #{$db_path}`
end

after = `/usr/bin/sqlite3 #{$db_path} "select browser, count(*) from history group by browser";`.strip
after = after.split("\n").inject({}) {|r, s| k, v = s.split("|"); r[k] = v.to_i; r}

puts
puts
after.each do |browser, count|
  puts "#{browser} now has #{count} (+#{count - (before[browser] || 0)})"
end

Dir.glob(File.expand_path("~/browser/*.csv")).map{|s| Pathname.new(s).unlink }

# 2023-07-01
#
# CREATE TABLE history (
#   id varchar(500) PRIMARY KEY,
#   signature TEXT NOT NULL UNIQUE,
#   url TEXT NOT NULL UNIQUE,
#   visited_at TEXT NOT NULL,
#   browser TEXT NOT NULL,
#   title TEXT
# );
#
# CREATE INDEX idx_title ON "history"(title)
# CREATE INDEX idx_url ON "history"(url)
# CREATE INDEX visited_at ON history(title)
#
#     /usr/bin/sqlite3 -list -separator ' â†’ ' $db <<EOF
# select
#   count(*) as count, strftime('%m %Y',datetime(history_visits.visit_time, 'unixepoch', '31 years')) as date
# from
#   history
# group by
#   strftime('%m%Y', datetime(visited_at, 'unixepoch', '31 years'))
# order by
#   count desc
# limit 1
# EOF
